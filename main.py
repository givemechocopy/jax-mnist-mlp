import jax.numpy as jnp
from config import config
from data.loader import get_mnist_data, get_mnist_test_data
from models.mlp import init_mlp_params, mlp
from utils.training import train
from utils.metrics import accuracy_fn
from utils.optimizer import create_optimizer
from utils.plotting import plot_training_curves

def main():
    # 1. ë°ì´í„° ë¡œë”©
    X_train, y_train, X_val, y_val = get_mnist_data()
    X_test, y_test = get_mnist_test_data()

    # 2. ëª¨ë¸ ë° ì˜µí‹°ë§ˆì´ì € ì„¤ì •
    config['model'] = mlp
    config['optimizer'] = create_optimizer(config['learning_rate'])

    # 3. íŒŒë¼ë¯¸í„° ì´ˆê¸°í™”
    params = init_mlp_params(config['key'], config['model_arch'])

    # 4. í•™ìŠµ ìˆ˜í–‰
    params, loss_history, val_acc_history, test_acc_history = train(
        params, X_train, y_train, X_val, y_val, X_test, y_test, config
    )

    # 5. ìµœì¢… ì •í™•ë„ ì¶œë ¥
    val_acc = accuracy_fn(params, jnp.array(X_val), jnp.array(y_val), config['model'])
    print(f"\nâœ… Final Validation Accuracy: {val_acc:.4f}")

    test_acc = accuracy_fn(params, jnp.array(X_test), jnp.array(y_test), config['model'])
    print(f"ğŸ§ª Final Test Accuracy: {test_acc:.4f}")

    # 6. í•™ìŠµ ê³¡ì„  ì‹œê°í™”
    plot_training_curves(
        loss_history,
        val_acc_history,
        test_acc_history,
        save_path="logs/result.png"
    )


if __name__ == "__main__":
    main()
